{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 1000 characters of CNT growth functions.pdf:\n",
      "Applied  Surface  Science  332  (2015)  756–760\n",
      "Contents  lists  available  at  ScienceDirect\n",
      "Applied  Surface  Science\n",
      "journal  h  om  epa  ge:  www.elsevier.com/locate/apsusc\n",
      "A  new understanding of  carbon  nanotube  growth:  Different  functions\n",
      "of\n",
      " carbon species\n",
      "Yueling  Zhanga,∗,  Baojun  Wangb,  Qing  Yuc,  Yajun  Tiand\n",
      "aCollege  of  Engineering,  Peking  University,  Summer  Palace  Road  5,  Beijing  100871,  PR  China\n",
      "bKey  Laboratory  of  Coal  Science  and  Technology,  Taiyuan  University  of  Technology,  Yingze  West  Street  79,  Taiyuan  030024,  PR  China\n",
      "cSchool  of  Chemistry  and  Chemical  Engineer  and  Center  of  Modern  Analysis,  Nanjing  University,  Hankou  Road  22,  Nanjing  210093,  PR  China\n",
      "dNational  Institute  of  Clean-and-low-carbon  Energy,  P.O.  Box  001  Shenhua  NICE,  Future  Science  &  Technology  Park,  Beijing  102209,  PR  China\n",
      "a r t  i  c  l  e  i  n  f  o\n",
      "Article history:\n",
      "Received\n",
      " 13  November  2014\n",
      "Received\n",
      " in  revised  form  12  \n",
      "\n",
      "\n",
      "First 1000 characters of CNT growth mechanism.pdf:\n",
      "Chemical Engineering Journal 445 (2022) 136807\n",
      "Available online 6 May 2022\n",
      "1385-8947/© 2022 Elsevier B.V. All rights reserved.Unraveling the mechanisms of carbon nanotube growth by chemical \n",
      "vapor deposition \n",
      "Georgios P. Gakis, Stefania Termine, Aikaterini-Flora A. Trompeta, Ioannis G. Aviziotis, \n",
      "Costas A. Charitidis* \n",
      "Research Lab of Advanced, Composite, Nano-Materials and Nanotechnology, Materials Science and Engineering Department, School of Chemical Engineering, National \n",
      "Technical University of Athens, 9 Heroon Polytechneiou Street, Zografos, Athens 15780, Greece   \n",
      "ARTICLE INFO  \n",
      "Keywords: \n",
      "CVD of CNTs \n",
      "Macroscopic model \n",
      "Growth mechanism \n",
      "Competitive phenomena \n",
      "Carbon diffusion \n",
      "Catalyst lifetime ABSTRACT  \n",
      "The mechanisms of carbon nanotube (CNT) growth by chemical vapor deposition of acetylene on Fe/SiO 2:Al2O3 \n",
      "(zeolite Y) catalyst are unraveled through a combined computational and experimental study. CNTs are syn-\n",
      "thesized in a horizontal reactor under atmospheric pressure w\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "\n",
    "# Extract text from PDFs in a folder\n",
    "def extract_text_from_pdfs(folder_path):\n",
    "    pdf_texts = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            pdf_file = os.path.join(folder_path, filename)\n",
    "            with open(pdf_file, \"rb\") as file:\n",
    "                pdf_reader = PyPDF2.PdfReader(file)\n",
    "                pdf_text = \"\"\n",
    "                for page_num in range(len(pdf_reader.pages)):\n",
    "                    page = pdf_reader.pages[page_num]\n",
    "                    pdf_text += page.extract_text()\n",
    "                pdf_texts.append({\"filename\": filename, \"text\": pdf_text})\n",
    "    return pdf_texts\n",
    "\n",
    "folder_path = \"./Data\"  # Replace with the path where your PDFs are stored\n",
    "pdf_texts = extract_text_from_pdfs(folder_path)\n",
    "\n",
    "for pdf in pdf_texts:\n",
    "    print(f\"First 1000 characters of {pdf['filename']}:\")\n",
    "    print(pdf['text'][:1000])  # Print the first 1000 characters for review\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VANI SETH\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPTNeoXForCausalLM, AutoTokenizer\n",
    "\n",
    "# Initialize GPT-NeoX model and tokenizer\n",
    "class GPTNeoXQA:\n",
    "    def __init__(self, model_name=\"EleutherAI/gpt-neox-20b\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = GPTNeoXForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "    def generate_response(self, question, context, max_length=512):\n",
    "        # Combine the question and context\n",
    "        input_text = f\"Context: {context}\\n\\nQuestion: {question}\\nAnswer: \"\n",
    "        \n",
    "        # Tokenize the input\n",
    "        inputs = self.tokenizer.encode(input_text, return_tensors=\"pt\", truncation=True, max_length=max_length)\n",
    "        \n",
    "        # Generate response using GPT-NeoX\n",
    "        outputs = self.model.generate(\n",
    "            inputs,\n",
    "            max_length=max_length,\n",
    "            num_beams=5,            # Beam search for quality responses\n",
    "            no_repeat_ngram_size=2, # Avoid repetition\n",
    "            early_stopping=True,\n",
    "            length_penalty=1.0,     # Penalize shorter responses\n",
    "        )\n",
    "        # Decode the output\n",
    "        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 156/156 [00:00<00:00, 154kB/s]\n",
      "c:\\Users\\VANI SETH\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\VANI SETH\\.cache\\huggingface\\hub\\models--EleutherAI--gpt-neox-20b. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "vocab.json: 100%|██████████| 1.08M/1.08M [00:00<00:00, 9.59MB/s]\n",
      "merges.txt: 100%|██████████| 457k/457k [00:00<00:00, 20.7MB/s]\n",
      "tokenizer.json: 100%|██████████| 2.11M/2.11M [00:00<00:00, 17.6MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 90.0/90.0 [00:00<?, ?B/s]\n",
      "config.json: 100%|██████████| 613/613 [00:00<?, ?B/s] \n",
      "model.safetensors.index.json: 100%|██████████| 60.4k/60.4k [00:00<?, ?B/s]\n",
      "model-00001-of-00046.safetensors: 100%|██████████| 926M/926M [01:01<00:00, 15.1MB/s]\n",
      "model-00002-of-00046.safetensors: 100%|██████████| 910M/910M [00:58<00:00, 15.6MB/s]\n",
      "model-00003-of-00046.safetensors: 100%|██████████| 910M/910M [00:58<00:00, 15.5MB/s]\n",
      "model-00004-of-00046.safetensors: 100%|██████████| 910M/910M [00:57<00:00, 15.9MB/s]\n",
      "model-00005-of-00046.safetensors: 100%|██████████| 910M/910M [00:57<00:00, 15.9MB/s]\n",
      "model-00006-of-00046.safetensors: 100%|██████████| 910M/910M [00:58<00:00, 15.7MB/s]\n",
      "model-00007-of-00046.safetensors: 100%|██████████| 910M/910M [00:56<00:00, 16.0MB/s]\n",
      "model-00008-of-00046.safetensors: 100%|██████████| 910M/910M [00:58<00:00, 15.5MB/s]\n",
      "model-00009-of-00046.safetensors: 100%|██████████| 910M/910M [01:05<00:00, 13.9MB/s]\n",
      "model-00010-of-00046.safetensors: 100%|██████████| 910M/910M [00:57<00:00, 15.7MB/s]\n",
      "model-00011-of-00046.safetensors: 100%|██████████| 910M/910M [00:57<00:00, 15.8MB/s]\n",
      "model-00012-of-00046.safetensors: 100%|██████████| 910M/910M [00:57<00:00, 15.7MB/s]\n",
      "model-00013-of-00046.safetensors: 100%|██████████| 910M/910M [01:00<00:00, 15.1MB/s]\n",
      "model-00014-of-00046.safetensors: 100%|██████████| 910M/910M [01:00<00:00, 15.1MB/s]\n",
      "model-00015-of-00046.safetensors: 100%|██████████| 910M/910M [00:56<00:00, 16.0MB/s]\n",
      "model-00016-of-00046.safetensors: 100%|██████████| 910M/910M [01:00<00:00, 15.2MB/s]\n",
      "model-00017-of-00046.safetensors: 100%|██████████| 910M/910M [00:57<00:00, 15.9MB/s]\n",
      "model-00018-of-00046.safetensors: 100%|██████████| 910M/910M [00:57<00:00, 15.9MB/s]\n",
      "model-00019-of-00046.safetensors: 100%|██████████| 910M/910M [00:57<00:00, 15.9MB/s]\n",
      "model-00020-of-00046.safetensors: 100%|██████████| 910M/910M [00:56<00:00, 16.0MB/s]\n",
      "model-00021-of-00046.safetensors: 100%|██████████| 910M/910M [00:57<00:00, 15.9MB/s]\n",
      "model-00022-of-00046.safetensors: 100%|██████████| 910M/910M [00:56<00:00, 16.0MB/s]\n",
      "model-00023-of-00046.safetensors: 100%|██████████| 910M/910M [00:56<00:00, 16.0MB/s]\n",
      "model-00024-of-00046.safetensors: 100%|██████████| 910M/910M [00:56<00:00, 16.0MB/s]\n",
      "model-00025-of-00046.safetensors: 100%|██████████| 910M/910M [00:56<00:00, 16.0MB/s]\n",
      "model-00026-of-00046.safetensors: 100%|██████████| 910M/910M [00:57<00:00, 15.8MB/s]\n",
      "model-00027-of-00046.safetensors: 100%|██████████| 910M/910M [00:56<00:00, 16.0MB/s]\n",
      "model-00028-of-00046.safetensors: 100%|██████████| 910M/910M [00:56<00:00, 16.0MB/s]\n",
      "model-00029-of-00046.safetensors: 100%|██████████| 910M/910M [00:57<00:00, 15.8MB/s]\n",
      "Downloading shards:  63%|██████▎   | 29/46 [28:12<16:18, 57.56s/it]c:\\Users\\VANI SETH\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:983: UserWarning: Not enough free disk space to download the file. The expected file size is: 910.33 MB. The target location C:\\Users\\VANI SETH\\.cache\\huggingface\\hub only has 405.26 MB free disk space.\n",
      "  warnings.warn(\n",
      "c:\\Users\\VANI SETH\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:983: UserWarning: Not enough free disk space to download the file. The expected file size is: 910.33 MB. The target location C:\\Users\\VANI SETH\\.cache\\huggingface\\hub\\models--EleutherAI--gpt-neox-20b\\blobs only has 405.26 MB free disk space.\n",
      "  warnings.warn(\n",
      "model-00030-of-00046.safetensors: 100%|██████████| 910M/910M [00:56<00:00, 16.0MB/s]\n",
      "Downloading shards:  65%|██████▌   | 30/46 [29:09<15:18, 57.43s/it]c:\\Users\\VANI SETH\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:983: UserWarning: Not enough free disk space to download the file. The expected file size is: 910.33 MB. The target location C:\\Users\\VANI SETH\\.cache\\huggingface\\hub only has 825.89 MB free disk space.\n",
      "  warnings.warn(\n",
      "c:\\Users\\VANI SETH\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:983: UserWarning: Not enough free disk space to download the file. The expected file size is: 910.33 MB. The target location C:\\Users\\VANI SETH\\.cache\\huggingface\\hub\\models--EleutherAI--gpt-neox-20b\\blobs only has 825.89 MB free disk space.\n",
      "  warnings.warn(\n",
      "model-00031-of-00046.safetensors:  92%|█████████▏| 839M/910M [00:52<00:04, 15.9MB/s]\n",
      "Downloading shards:  65%|██████▌   | 30/46 [30:02<16:01, 60.08s/it]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Run the pipeline\u001b[39;00m\n\u001b[0;32m     19\u001b[0m folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./Data\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Replace with the actual folder path containing your PDFs\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[43mqa_pipeline_with_gpt_neox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m, in \u001b[0;36mqa_pipeline_with_gpt_neox\u001b[1;34m(folder_path)\u001b[0m\n\u001b[0;32m      3\u001b[0m pdf_texts \u001b[38;5;241m=\u001b[39m extract_text_from_pdfs(folder_path)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Initialize GPT-NeoX model for QA and response generation\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m gpt_neox_qa \u001b[38;5;241m=\u001b[39m \u001b[43mGPTNeoXQA\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pdf \u001b[38;5;129;01min\u001b[39;00m pdf_texts:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Processing PDF: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m, in \u001b[0;36mGPTNeoXQA.__init__\u001b[1;34m(self, model_name)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEleutherAI/gpt-neox-20b\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mGPTNeoXForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\VANI SETH\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_utils.py:2585\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2582\u001b[0m \u001b[38;5;66;03m# We'll need to download and cache each checkpoint shard if the checkpoint is sharded.\u001b[39;00m\n\u001b[0;32m   2583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sharded:\n\u001b[0;32m   2584\u001b[0m     \u001b[38;5;66;03m# rsolved_archive_file becomes a list of files that point to the different checkpoint shards in this case.\u001b[39;00m\n\u001b[1;32m-> 2585\u001b[0m     resolved_archive_file, sharded_metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_checkpoint_shard_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2591\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2593\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2594\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2596\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2597\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2598\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2600\u001b[0m \u001b[38;5;66;03m# load pt weights early so that we know which dtype to init the model under\u001b[39;00m\n\u001b[0;32m   2601\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_pt:\n",
      "File \u001b[1;32mc:\\Users\\VANI SETH\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\hub.py:958\u001b[0m, in \u001b[0;36mget_checkpoint_shard_files\u001b[1;34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, use_auth_token, user_agent, revision, subfolder, _commit_hash)\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m shard_filename \u001b[38;5;129;01min\u001b[39;00m tqdm(shard_filenames, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading shards\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    957\u001b[0m         \u001b[38;5;66;03m# Load from URL\u001b[39;00m\n\u001b[1;32m--> 958\u001b[0m         cached_filename \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshard_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_commit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m     \u001b[38;5;66;03m# We have already dealt with RepositoryNotFoundError and RevisionNotFoundError when getting the index, so\u001b[39;00m\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;66;03m# we don't have to catch them here.\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError:\n",
      "File \u001b[1;32mc:\\Users\\VANI SETH\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\hub.py:417\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[0;32m    414\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    416\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 417\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    434\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    435\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    436\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass a token having permission to this repo with `use_auth_token` or log in with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`huggingface-cli login` and pass `use_auth_token=True`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    438\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\VANI SETH\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\VANI SETH\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1457\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[0;32m   1454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m local_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1455\u001b[0m             _check_disk_space(expected_size, local_dir)\n\u001b[1;32m-> 1457\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemp_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m local_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1467\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStoring \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mblob_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\VANI SETH\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:527\u001b[0m, in \u001b[0;36mhttp_get\u001b[1;34m(url, temp_file, proxies, resume_size, headers, expected_size, _nb_retries)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunk:  \u001b[38;5;66;03m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[0;32m    526\u001b[0m     progress\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n\u001b[1;32m--> 527\u001b[0m     \u001b[43mtemp_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m     new_resume_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;66;03m# Some data has been downloaded from the server so we reset the number of retries.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\VANI SETH\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\tempfile.py:483\u001b[0m, in \u001b[0;36m_TemporaryFileWrapper.__getattr__.<locals>.func_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;129m@_functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "def qa_pipeline_with_gpt_neox(folder_path):\n",
    "    # Extract text from PDFs\n",
    "    pdf_texts = extract_text_from_pdfs(folder_path)\n",
    "\n",
    "    # Initialize GPT-NeoX model for QA and response generation\n",
    "    gpt_neox_qa = GPTNeoXQA()\n",
    "\n",
    "    for pdf in pdf_texts:\n",
    "        print(f\"\\n--- Processing PDF: {pdf['filename']} ---\\n\")\n",
    "        \n",
    "        # Define your question (this can be dynamic or user-input)\n",
    "        question = \"What is the growth temperature for carbon nanotubes?\"\n",
    "\n",
    "        # Generate a response using GPT-NeoX (it will answer the question and provide detail)\n",
    "        response = gpt_neox_qa.generate_response(question, pdf['text'])\n",
    "        print(f\"GPT-NeoX Generated Response: {response}\\n\")\n",
    "\n",
    "# Run the pipeline\n",
    "folder_path = \"./Data\"  # Replace with the actual folder path containing your PDFs\n",
    "qa_pipeline_with_gpt_neox(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
